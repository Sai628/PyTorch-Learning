{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建 ResNet34 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable as V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    实现子module: Residual Block\n",
    "    \"\"\"\n",
    "    def __init__(self, inchannel, outchannel, stride=1, shortcut=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inchannel, out_channels=outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=outchannel, out_channels=outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.right = shortcut\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        residual = x if self.right is None else self.right(x)\n",
    "        out += residual\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    实现主module: ResNet34\n",
    "    ResNet34 包含多个layer, 每个layer又包含多个residual block\n",
    "    用子module来实现residual block, 用 _make_layer 函数来实现layer\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        # 前几层图像转换\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # 重复的layer, 分别有3, 4, 6, 3个residual block\n",
    "        self.layer1 = self._make_layer(64, 64, 3)\n",
    "        self.layer2 = self._make_layer(64, 128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 6, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 3, stride=2)\n",
    "        \n",
    "        # 分类用的全连接\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, inchannel, outchannel, block_num, stride=1):\n",
    "        \"\"\"\n",
    "        构建layer, 包含多个residual block\n",
    "        \"\"\"\n",
    "        shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inchannel, out_channels=outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(inchannel, outchannel, stride, shortcut))\n",
    "        \n",
    "        for i in range(1, block_num):\n",
    "            layers.append(ResidualBlock(outchannel, outchannel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pre(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = F.avg_pool2d(x, 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0929, -0.3950, -0.4729,  0.2882,  0.6009,  0.3002, -0.4543,  0.1153,\n",
       "          0.0312,  0.4376,  0.1768, -0.2627, -0.2493, -0.1421,  0.2670,  0.2711,\n",
       "         -0.0501, -0.3412,  0.1692, -0.4811,  0.6108,  0.3615, -0.1746, -0.2344,\n",
       "         -0.0274, -0.2285, -0.1108,  0.1980,  0.2553, -0.1237, -0.3556, -0.2574,\n",
       "          0.6607,  0.2911, -0.4118, -0.1778,  0.4043,  0.0296, -0.0504,  0.2192,\n",
       "          0.5743,  0.4202,  0.3013,  0.1235,  0.2005,  0.0277, -0.6493,  0.0194,\n",
       "         -0.5937, -0.1689, -0.1596, -0.2347, -0.0337, -0.0198, -0.5159, -0.1307,\n",
       "          0.0596, -0.0886,  0.3157, -0.0831,  0.1781, -0.5370,  0.2013,  0.2319,\n",
       "          0.1822,  0.2965,  0.4196,  0.0318, -0.0034, -0.1987,  0.3365,  0.3040,\n",
       "         -0.0060,  0.1097, -0.4706,  0.2856, -0.4423,  0.3514,  0.0030,  0.2723,\n",
       "         -0.0355,  0.4009,  0.0014,  0.3805,  0.5891, -0.4170,  0.7524, -0.3346,\n",
       "          0.1126, -0.1750,  0.2317,  0.2606, -0.2347, -0.6723, -0.2562,  0.5006,\n",
       "          0.4379,  0.1141,  0.4111, -0.1531, -0.1026,  0.3775,  0.0262, -0.0678,\n",
       "          0.0352,  0.4576, -0.4004,  0.1818, -0.0142,  0.0568,  0.4933, -0.0466,\n",
       "          0.0681, -0.0566,  0.3897, -0.3675,  0.6352, -0.4263,  0.1928, -0.5308,\n",
       "          0.2789,  0.3288,  0.1230, -0.1587,  0.3583, -0.0602, -0.2914, -0.1704,\n",
       "          0.2964,  0.7373,  0.1059, -0.0323, -0.2983, -0.2989, -0.0739,  0.3007,\n",
       "          0.1438, -0.1057, -0.1299,  0.2089, -0.0991,  0.0031, -0.3015, -0.0705,\n",
       "          0.1027, -0.5325,  0.2200, -0.2971, -0.0553, -0.1777,  0.4264, -0.5648,\n",
       "          0.2558,  0.0363, -0.0459,  0.2243,  0.0848,  0.3350, -0.2724, -0.1270,\n",
       "         -0.1168, -0.0357, -0.2194, -0.7469, -0.3801, -0.3704,  0.5033, -0.7543,\n",
       "          0.2061, -0.0298, -0.0785, -0.0889,  0.6474,  0.2289,  0.0149, -0.1856,\n",
       "          0.1493,  0.4011, -0.4169,  0.5267, -0.4477,  0.3989, -0.0884,  0.2338,\n",
       "         -0.2985,  0.4214, -0.1315,  0.1687,  0.0201, -0.2323, -0.3842,  0.5338,\n",
       "          0.2595, -0.0488,  0.7111, -0.1748,  0.4842,  0.3111,  0.0859,  0.3961,\n",
       "         -0.6184, -0.2457,  0.3348, -0.4697, -0.1132,  0.2155, -0.0255,  0.6170,\n",
       "          0.8343, -0.1057,  0.2625, -0.7389, -0.2874,  0.0364,  0.3594, -0.1832,\n",
       "         -0.2904, -0.3310,  0.1976,  0.0277, -0.4607, -0.3459,  0.2000, -0.3520,\n",
       "         -0.2640,  0.3972,  0.0046, -0.3427,  0.2377, -0.0738,  0.6779, -0.4293,\n",
       "         -0.6095, -0.9065, -0.2070,  0.3778,  0.3499, -0.7291, -0.0405,  0.6010,\n",
       "          0.0902, -0.1954,  0.0586, -0.2300, -0.2943,  0.5754, -0.6135, -0.5264,\n",
       "         -0.7613, -0.2401,  0.5788,  0.0718,  0.3190, -0.3283, -0.0235, -0.2470,\n",
       "         -0.6013,  0.0642,  0.0410,  0.0228, -0.5257,  0.3446, -0.0320,  0.5782,\n",
       "         -0.0734,  0.4256, -0.0636, -0.2451,  0.1862,  0.2331,  0.2110, -0.7409,\n",
       "         -0.4060, -0.0804,  0.0022, -0.0666,  0.3563, -0.0310, -0.0317, -0.1837,\n",
       "          0.2973, -0.1350, -0.0493, -0.2613,  0.0039,  0.0065, -1.0347, -0.2369,\n",
       "         -0.5334,  0.4075, -0.4672, -0.7221, -0.0555,  0.3015,  0.1990, -0.0298,\n",
       "          0.1323,  0.1382,  0.1391,  0.1562, -0.0725, -0.0591, -0.0379, -0.6363,\n",
       "         -0.3162, -0.8260,  0.3619, -0.4507, -0.2514, -0.1107,  0.2040, -0.0766,\n",
       "         -0.0381,  0.0531,  0.0170,  0.5394,  0.5144,  0.2080,  0.4291,  0.3833,\n",
       "          0.0778,  0.0317, -0.1002, -0.4388, -0.0971, -0.7483,  0.0220, -0.0811,\n",
       "          0.8038, -0.2782, -0.1089,  0.4463, -0.2311, -0.2467,  0.1436,  0.2080,\n",
       "          0.4646, -0.2564, -0.1542,  0.1504, -0.0541,  0.0609,  0.4247, -0.1556,\n",
       "          0.3070,  0.1476,  0.6081,  0.1786,  0.0869,  0.3254,  0.0375, -0.5619,\n",
       "         -0.1437, -0.2359, -0.0561,  0.0273, -0.0857,  0.0767,  0.6137, -0.4557,\n",
       "         -0.1130, -0.4363,  0.1640,  0.2175, -0.3350,  0.2303,  0.3216,  0.0238,\n",
       "         -0.5189,  0.1527,  0.3388, -0.3214, -0.0414,  0.0280,  0.3714,  0.2103,\n",
       "         -0.3331,  0.0115, -0.2726,  0.1747, -0.5450,  0.3532,  0.0252, -0.3449,\n",
       "          0.1221, -0.0985,  0.0404, -0.0814, -0.4102, -0.3316, -0.2104, -0.0972,\n",
       "         -0.7454,  0.4044, -0.0746,  0.2445,  0.4927, -0.7002,  0.2230,  0.2821,\n",
       "         -0.2143, -0.1005, -0.6979, -0.1240,  0.3754, -0.1120, -0.1521,  0.2159,\n",
       "         -0.1450, -0.3242, -0.0805,  0.3915,  0.3543,  0.1072, -0.6289,  0.3755,\n",
       "          0.3479,  0.5853, -0.6370, -0.3802,  0.8426, -0.1607,  0.3779, -0.0024,\n",
       "         -0.1257, -0.0537, -0.1439,  0.5232,  0.4281, -0.0827, -0.4982, -0.1031,\n",
       "          0.2098, -0.2914, -0.2991,  0.0051, -0.3379, -0.6657,  0.0276,  0.2928,\n",
       "         -0.2882,  0.0427, -0.1774, -0.2909,  0.2921,  0.1694, -0.1277,  0.1924,\n",
       "         -1.0630, -0.1420,  0.1001, -0.3095,  0.2743, -0.2981, -0.1084, -0.0399,\n",
       "         -0.6020,  0.7361, -0.3434,  0.1022,  0.2718,  0.2178, -0.1282,  0.0789,\n",
       "          0.3019,  0.3135,  0.4037,  0.3814,  0.2024, -0.6198, -0.5632,  0.4643,\n",
       "          0.1384,  0.3881, -0.3138,  0.2223,  0.2839, -0.1717,  0.6917,  0.0163,\n",
       "          0.2698,  0.1143,  0.0660,  0.1350,  0.6416,  0.1622,  0.0344, -0.2863,\n",
       "          0.1747,  0.3422,  0.1778,  0.5396, -0.1272,  0.0952,  0.1691,  0.6085,\n",
       "         -0.3743,  0.3057, -0.6680, -0.0498,  0.5744, -0.2359,  0.8823,  0.1666,\n",
       "          0.0102, -0.3109,  0.1829, -0.0720,  0.0394, -0.2558,  0.0166,  0.2599,\n",
       "         -0.1901, -0.0528, -0.5748, -0.1671, -0.0986,  0.0592,  0.0468, -0.1310,\n",
       "          0.2260, -0.0418,  0.2545, -0.2150, -0.1027,  0.1389,  0.3281, -0.0891,\n",
       "          0.0197, -0.0332, -0.0077, -0.3419,  0.1562,  0.0377, -0.1129,  0.4873,\n",
       "         -0.4214,  0.1365, -0.5324,  0.0965, -0.5080, -0.0212,  0.1453, -0.3344,\n",
       "         -0.3824, -0.5360,  0.4790,  0.2265,  0.3288,  0.2701, -0.4052,  0.7594,\n",
       "         -0.3719, -0.5091, -0.0615,  0.1347, -0.3319,  0.5351,  0.0078,  0.1180,\n",
       "         -0.2366, -0.3032,  0.6109,  0.0488, -0.5483,  0.2064,  0.3230, -0.5123,\n",
       "          0.2292, -0.4116, -0.6384, -0.0247,  0.5865,  0.0176, -0.1899,  0.1026,\n",
       "         -0.2600,  0.2579, -0.0973, -0.5709, -0.1731, -0.3204,  0.6975,  0.0774,\n",
       "          0.2186,  0.1413,  0.0897, -0.3599, -0.0467, -0.7418,  0.0302,  0.7579,\n",
       "          0.2951, -0.1724, -0.1898,  0.3373,  0.3403,  0.2555,  0.1337, -0.1957,\n",
       "         -0.1660,  0.5181,  0.4976,  0.2028,  0.1394,  0.1936,  0.5562, -0.1792,\n",
       "          0.2508,  0.2322,  0.3658,  0.4774,  0.3603, -0.4232,  0.2695, -0.0109,\n",
       "          0.2417,  0.6249, -0.2379, -0.6794,  0.1502,  0.1148, -0.3434,  0.3005,\n",
       "         -0.0443, -0.4732,  0.0579, -0.2341, -0.1134,  0.3282,  0.1088, -0.1279,\n",
       "         -0.2881,  0.2816, -0.0303, -0.0353, -0.0077,  0.5590, -0.2977,  0.1704,\n",
       "          0.1218, -0.4888,  0.2971, -0.0675, -0.6583, -0.0897, -0.2550, -0.0719,\n",
       "          0.2070,  0.3070,  0.2440, -0.0648, -0.5453, -0.5097,  0.1880, -0.0582,\n",
       "         -0.2579,  0.0561, -0.0646, -0.2263,  0.1995, -0.1129,  0.4521, -0.2546,\n",
       "          0.0169,  0.0437,  0.1475, -0.7223,  0.5198, -0.2834, -0.3235, -1.0891,\n",
       "          0.0574, -0.2471, -0.0221,  0.0244, -0.2197, -0.3612,  0.0494,  0.0778,\n",
       "         -0.8438, -0.3491, -0.0693,  0.7940,  0.3209,  0.3849,  0.0294,  0.8019,\n",
       "          0.4909,  0.2997,  0.2509,  0.1678, -0.1482, -0.3433, -0.0010, -0.3282,\n",
       "          0.1465, -0.6382,  0.1076,  0.0749,  0.4334,  0.4297, -0.3596,  0.6883,\n",
       "          0.1042, -0.6351,  0.6651, -0.6025, -0.5599, -0.3245,  0.1232, -0.2287,\n",
       "         -0.7294, -0.4789, -0.4281, -0.1654, -0.1139,  0.4186,  0.1523, -0.2548,\n",
       "          0.2140,  0.6588,  0.0044,  0.0720,  0.2995, -0.1131, -0.1740, -0.0720,\n",
       "         -0.3581, -0.8491, -0.2367,  0.3917,  0.4523,  0.2919, -0.1446,  0.5282,\n",
       "         -0.1659,  0.3814, -0.2263, -0.2074, -0.0655,  0.5352,  0.3333,  0.0812,\n",
       "          0.1834,  0.1550, -0.8289,  0.2801, -0.2432, -0.5131, -0.5213,  0.1201,\n",
       "          0.0846, -0.0343, -0.3040, -0.0935, -0.2213, -0.7172,  0.0385,  0.1525,\n",
       "         -0.0299, -0.2344, -0.1297, -0.4468,  0.3850, -0.0127,  0.1875, -0.1775,\n",
       "         -0.2609,  0.5419,  0.4543,  0.0849,  0.2203,  0.4049, -0.3992, -0.3884,\n",
       "         -0.3824,  0.7320,  0.0859, -0.1726,  0.0374,  0.1082,  0.1968, -0.6996,\n",
       "         -0.3586, -0.1170,  0.5020,  0.1065, -0.8889, -0.1423, -0.2255, -0.0719,\n",
       "          0.0231,  0.1345, -0.3411,  0.4296, -0.5741,  0.2806,  0.3631, -0.1442,\n",
       "          0.7305, -0.2523, -0.1327,  0.3337,  0.1436, -0.2890, -0.1836, -0.2361,\n",
       "         -0.2560,  0.0374, -0.4435,  0.2681, -0.1456, -0.0694, -0.6718,  0.0825,\n",
       "         -0.4442,  0.1557, -0.1869,  0.6626, -0.1546, -0.6417,  0.6024,  0.7149,\n",
       "          0.1170, -0.1509, -0.2820,  0.0792, -0.6172, -0.0197, -0.1969,  0.1296,\n",
       "          0.5371, -0.0284,  0.2728, -0.5015,  0.1348,  0.2933,  0.2389,  0.0827,\n",
       "          0.0222, -0.6192, -0.2693,  0.0565,  0.2544, -0.3296, -0.6367, -0.3261,\n",
       "          0.1768, -0.4250,  0.3129,  0.2384, -0.0135,  0.3428,  0.1820, -0.1845,\n",
       "         -0.2102, -0.0202,  0.3088, -0.3693,  0.2862, -0.2726,  0.6038, -0.6250,\n",
       "         -0.0409, -0.4691,  0.1238, -0.7415,  0.3157, -0.9369, -0.3299, -0.0520,\n",
       "         -1.0198,  0.1493, -0.1666,  0.1483, -0.2698, -0.1814,  0.3132,  0.2677,\n",
       "         -0.3787, -0.1106, -0.2661, -0.0087,  0.0669,  0.0468,  0.1058,  0.1218,\n",
       "         -0.2370, -0.3990,  0.1528, -0.3902, -0.3970, -0.4741,  0.5377, -0.2936,\n",
       "          0.3549,  0.0360,  0.0937,  0.6384, -0.1240, -0.0165, -0.0388, -0.1033,\n",
       "          0.2186,  0.2634,  0.3844,  0.3327, -0.2534, -0.3155,  0.0891,  0.2090,\n",
       "          0.4311, -0.0039,  0.2135,  0.4098, -0.2318,  0.0354,  0.0054, -0.0300,\n",
       "         -0.5274,  0.3243,  0.1207,  0.1149,  0.3712, -0.1215, -0.3071,  0.0719,\n",
       "          0.3539,  0.0327,  0.1053, -0.4652, -0.1518, -0.2784, -0.2609, -0.4604,\n",
       "         -0.0917,  0.2863, -0.1138, -0.4609,  0.0240, -0.4365,  0.4553,  0.0294,\n",
       "         -0.0714, -0.4435, -0.0911,  0.0406,  0.0833,  0.2298,  0.1868, -0.5254,\n",
       "          0.4760, -0.2425,  0.2315,  0.4483,  0.1477, -0.3128,  0.0303, -0.0216,\n",
       "          0.2929, -0.0523, -0.1969,  0.5356,  0.0564, -0.3034, -0.3492, -0.1733,\n",
       "         -0.1455, -0.0439,  0.1953,  0.1853, -0.5906, -0.2504, -0.3065, -0.2768,\n",
       "         -0.2547,  0.0810,  0.4750,  0.3201,  0.5309, -0.3372,  0.0827, -0.0440,\n",
       "         -0.0621, -0.2964,  0.0119, -0.2347,  0.6452, -0.0827,  0.0781,  0.3304,\n",
       "         -0.0237,  0.3016, -0.1959,  0.6793,  0.4899,  0.3431,  0.1494,  0.0766]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet()\n",
    "input = V(t.randn(1, 3, 224, 224))\n",
    "out = model(input)\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-learning",
   "language": "python",
   "name": "pytorch-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
