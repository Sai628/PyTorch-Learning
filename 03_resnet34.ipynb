{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 搭建 ResNet34 网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch as t\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable as V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    实现子module: Residual Block\n",
    "    \"\"\"\n",
    "    def __init__(self, inchannel, outchannel, stride=1, shortcut=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.left = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inchannel, out_channels=outchannel, kernel_size=3, stride=stride, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=outchannel, out_channels=outchannel, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        self.right = shortcut\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.left(x)\n",
    "        residual = x if self.right is None else self.right(x)\n",
    "        out += residual\n",
    "        return F.relu(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "    实现主module: ResNet34\n",
    "    ResNet34 包含多个layer, 每个layer又包含多个residual block\n",
    "    用子module来实现residual block, 用 _make_layer 函数来实现layer\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(ResNet, self).__init__()\n",
    "        # 前几层图像转换\n",
    "        self.pre = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=3, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # 重复的layer, 分别有3, 4, 6, 3个residual block\n",
    "        self.layer1 = self._make_layer(64, 64, 3)\n",
    "        self.layer2 = self._make_layer(64, 128, 4, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, 6, stride=2)\n",
    "        self.layer4 = self._make_layer(256, 512, 3, stride=2)\n",
    "        \n",
    "        # 分类用的全连接\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "    \n",
    "    def _make_layer(self, inchannel, outchannel, block_num, stride=1):\n",
    "        \"\"\"\n",
    "        构建layer, 包含多个residual block\n",
    "        \"\"\"\n",
    "        shortcut = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=inchannel, out_channels=outchannel, kernel_size=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(inchannel, outchannel, stride, shortcut))\n",
    "        \n",
    "        for i in range(1, block_num):\n",
    "            layers.append(ResidualBlock(outchannel, outchannel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.pre(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = F.avg_pool2d(x, 7)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5078, -0.0444, -0.1475, -0.6192,  0.6766, -0.3655,  0.4035,  0.2271,\n",
       "         -0.3594,  0.1724,  0.0050, -0.4060,  0.4394,  0.2365, -0.1953, -0.4293,\n",
       "         -0.3881, -0.4816, -0.1599, -0.1557,  0.2584, -0.4328,  0.1026, -0.0159,\n",
       "          0.0008, -0.1843,  0.2043, -0.1995, -0.1417, -0.5246,  0.1327, -0.0158,\n",
       "         -0.0346,  0.1849, -0.1738, -0.4253, -0.0453, -0.1171,  0.1861, -0.2695,\n",
       "         -0.5154, -0.4277,  0.4693,  0.2242, -0.0932,  0.0968, -0.1271, -0.3864,\n",
       "          0.1029, -0.5248, -0.0107,  0.2686,  0.7145, -0.1095,  0.2055,  0.0953,\n",
       "         -0.7000, -0.1644, -0.0966, -0.0216,  0.3671,  0.2210,  0.6721, -0.2888,\n",
       "         -0.3524, -0.1813,  0.3751, -0.2300, -0.0895, -0.5230,  0.0012,  0.0267,\n",
       "         -0.3087, -0.3349, -0.3700,  0.1403, -0.2747,  0.0942,  0.4063,  0.0157,\n",
       "          0.3292, -0.2051,  0.0263, -0.3033,  0.5155, -0.2181,  0.5700,  0.1077,\n",
       "          0.1490, -0.2801,  0.2373, -0.0859,  0.1237, -0.2202, -0.4983,  0.3384,\n",
       "          0.0907, -0.2956, -0.1654, -0.0659, -0.1216, -0.3972, -0.0652,  0.1702,\n",
       "         -0.0674, -0.6866, -0.1429,  0.4022,  0.3945,  0.4502, -0.1520,  0.1506,\n",
       "         -0.0856, -0.1893, -0.6487, -0.3961, -0.5195, -0.1753, -0.1362,  0.0666,\n",
       "          0.4662,  0.0821,  0.1593,  0.1297,  0.1740, -0.3764, -0.5374, -0.5787,\n",
       "         -0.5166, -0.5302,  0.3078, -0.4292, -0.7306, -0.3076,  0.0557,  0.2569,\n",
       "          0.1585,  0.0878,  0.1222,  0.6571,  0.3102, -0.7995,  0.1063, -0.5465,\n",
       "          0.0426, -0.3411, -0.4003, -0.1757,  0.3513,  0.0307, -0.1793, -0.0403,\n",
       "          0.3875, -0.7896,  0.6247, -0.3317, -0.1098, -0.2373, -0.1724, -0.0778,\n",
       "         -0.1096,  0.0086,  0.1191,  0.0524,  0.0555, -0.1890, -0.3327,  0.4193,\n",
       "         -0.0928, -0.3558,  0.1651,  0.3892,  0.0104, -0.2809,  0.2670, -0.1419,\n",
       "          0.0622, -0.2060, -0.1494,  0.1048,  0.4032,  0.0068, -0.1395, -0.0632,\n",
       "          0.3265,  0.0815, -0.0266, -0.3546, -0.0087,  0.1583,  0.2619, -0.2100,\n",
       "          0.1010,  0.3031,  0.2944,  0.0467,  0.2006,  0.3124,  0.0712,  0.0184,\n",
       "         -0.0724, -0.6965, -0.1399, -0.0715, -0.2640,  0.1722,  0.2879, -0.5052,\n",
       "         -0.0294,  0.1493, -0.0869,  0.2625, -0.0721, -0.3238, -0.0784,  0.4770,\n",
       "          0.2574, -0.2356, -0.0967, -0.1236, -0.7370,  0.2620, -0.1198, -0.1612,\n",
       "          0.2920, -0.5327, -0.6430, -0.5009, -0.1312,  0.4846, -0.0108,  0.2822,\n",
       "          0.2654, -0.6946, -0.1034,  0.2471,  0.2649,  0.3295,  0.2497,  0.2567,\n",
       "          0.3221, -0.1986,  0.2358,  0.1285, -0.2720,  0.4203, -0.1480,  0.2321,\n",
       "         -0.2163,  0.0302, -0.1236,  0.3700,  0.6047,  0.2459,  0.1081, -0.1359,\n",
       "         -0.0202,  0.0771,  0.0208, -0.4327,  0.0248,  0.0144, -0.0306, -0.1114,\n",
       "         -0.3482, -0.4540,  0.1356,  0.1860, -0.3033, -0.4381, -0.1702, -0.4868,\n",
       "          0.3097,  0.2441,  0.1210, -0.4445,  0.0287,  0.1458,  0.1345,  0.3600,\n",
       "          0.7368, -0.0219,  0.0812, -0.1602,  0.1610,  0.3353,  0.1715,  0.6245,\n",
       "         -0.4255, -0.7092,  0.1975, -0.0069, -0.3040, -0.4888, -0.0243,  0.3096,\n",
       "         -0.0622, -0.2161,  0.0591,  0.1757, -0.2586, -0.3688, -0.8207, -0.1231,\n",
       "          0.2066,  0.4737, -0.3566, -0.1144, -0.1401, -0.2107,  0.4135, -0.2087,\n",
       "         -0.0604, -0.1265,  0.2094,  0.2594, -0.7738, -0.3858, -0.0539, -0.3699,\n",
       "         -0.0418, -0.0973, -0.7321, -0.1671, -0.2492, -0.1685, -0.0944,  0.0301,\n",
       "          0.8532,  0.6632,  0.3548, -0.3339, -0.0782, -0.4142,  0.2814, -0.0246,\n",
       "         -0.1783, -0.4188,  0.1360, -0.2611, -0.0113, -0.3201,  0.2389,  0.7352,\n",
       "         -0.1450, -0.2197,  0.0774,  0.1473, -0.2705,  0.4710,  0.1972, -0.4296,\n",
       "          0.4468,  0.3491,  0.4715,  0.0650,  0.2309, -0.0607, -0.5460,  0.0557,\n",
       "         -0.0850, -0.3963, -0.7007,  0.3484,  0.1772,  0.5342,  0.5158, -0.1767,\n",
       "          0.2656,  0.2039, -0.4873, -0.0992,  0.1364, -0.2309, -0.8149, -0.1441,\n",
       "          0.0176, -0.5263, -0.0544,  0.4150, -0.1452,  0.2777, -0.1501, -0.1431,\n",
       "         -0.2856,  0.4585, -0.0749,  0.5683, -0.1060,  0.2487,  0.6253, -0.2327,\n",
       "         -0.4597, -0.5345, -0.0519,  0.3071,  0.4012, -0.1691, -0.0233,  0.2344,\n",
       "         -0.0427,  0.0718, -0.0181, -0.1503, -0.0004, -0.2063, -0.0056, -0.1479,\n",
       "         -0.1691, -0.2074,  0.4214,  0.3063, -0.1831,  0.1050,  0.3453, -0.2174,\n",
       "         -0.0033,  0.2410, -0.1708,  0.1870,  0.5899,  0.1876, -0.1240,  0.0712,\n",
       "         -0.1410,  0.3686, -0.8071,  0.1940, -0.0390, -0.3631,  0.1144, -0.0518,\n",
       "          0.1279, -0.2163, -0.4143,  0.0774, -0.2190, -0.1123,  0.0231, -0.4628,\n",
       "         -0.6711, -0.1491, -0.2953, -0.3638,  0.3663,  0.2429,  0.5147,  0.1017,\n",
       "         -0.7059,  0.2275,  0.4061, -0.0174,  0.2885,  0.2618, -0.2021, -0.2827,\n",
       "          0.3939, -0.4859,  0.4043, -0.4584,  0.0384,  0.4550, -0.2301, -0.4704,\n",
       "         -0.3876,  0.0410,  0.3751,  0.1186, -0.3195, -0.1973,  1.0457,  0.0929,\n",
       "         -0.5854, -0.0392,  0.0791,  0.6303, -0.0757, -0.0087,  0.4235, -0.2795,\n",
       "          0.1682, -0.4818,  0.2247,  0.2664,  0.1925,  0.4770, -0.3553, -0.2795,\n",
       "         -0.2748,  0.1800, -0.3372,  0.2233, -0.5137, -0.4653,  0.2708,  0.1098,\n",
       "          0.5128,  0.5297, -0.2603, -0.4932,  0.3266, -0.3497,  0.1769,  0.0102,\n",
       "         -0.5654,  0.2871,  0.0843, -0.2309,  0.3157,  0.4015,  0.2624,  0.1315,\n",
       "         -0.1219,  0.3814,  0.4638,  0.3449,  0.3315,  0.2109,  0.1827, -0.1176,\n",
       "          0.2262, -0.5305,  0.0137, -0.1537,  0.0400,  0.3338, -0.1442,  0.1240,\n",
       "         -0.1144,  0.0962, -0.3235,  0.3171,  0.4411, -0.3502,  0.2155, -0.4688,\n",
       "          0.0193, -0.4972,  0.4155,  0.0580,  0.1832,  0.2196, -0.2072,  0.1448,\n",
       "         -0.1766, -0.2028, -0.1779, -0.0521,  0.3070, -0.1231, -0.5127, -0.1685,\n",
       "         -0.8930, -0.8065, -0.2173,  0.2011, -0.1289, -0.0240,  0.0798,  0.1246,\n",
       "          0.1075, -0.4920,  0.0514, -0.1350, -0.1661, -0.1971,  0.0342,  0.5099,\n",
       "          0.1352, -0.0116, -0.1256,  0.1473, -0.3051, -0.3088,  0.0986, -0.1843,\n",
       "          0.6557, -0.5595,  0.5416, -0.2481, -0.6273, -0.1707,  0.1937,  0.1596,\n",
       "         -0.3596,  0.2324, -0.3620, -0.4350,  0.2134,  0.2761,  0.1170,  0.3562,\n",
       "          0.2792, -0.1589,  0.5434, -0.0714,  0.1468, -0.1053, -0.0117,  0.4483,\n",
       "          0.4100,  0.2654, -0.0378, -0.1790,  0.1583,  0.5680,  0.1249,  0.2645,\n",
       "         -0.2406, -0.3219, -0.0713, -0.0582, -0.3047,  0.8853,  0.4185, -0.7039,\n",
       "         -0.1702,  0.2201,  0.4444,  0.8216,  0.2326, -0.0007, -0.0406,  0.2093,\n",
       "         -0.1578,  0.0050,  0.4408,  0.0651, -0.0390,  0.0230,  0.0822,  0.3477,\n",
       "         -0.3224, -0.2757, -0.3246, -0.0754, -0.0338, -0.0897,  0.1452, -0.6272,\n",
       "         -0.1911,  0.4141, -0.0688,  0.4338,  0.3645,  0.2029, -0.1117,  0.0914,\n",
       "         -0.2909, -0.6894, -0.7584, -0.0549, -0.1861,  0.1397, -0.1342,  0.3436,\n",
       "         -0.1802, -0.1582,  0.2906,  0.0983,  0.6397,  0.1085,  0.0474,  0.4263,\n",
       "         -0.9387, -0.3586, -0.5992,  0.1198, -0.1070,  0.1559,  0.3927, -0.2667,\n",
       "         -0.0838,  0.1404,  0.1725, -0.2023, -0.3718, -0.1004, -0.0037, -0.5126,\n",
       "         -0.5657, -0.2973,  0.1232,  0.2391,  0.1175,  0.1393,  0.0737, -0.4157,\n",
       "         -0.0280,  0.6948,  0.3633, -0.4073,  0.4329,  0.0340,  0.3716,  0.0718,\n",
       "          0.1240, -0.3227,  0.0848,  0.0484, -0.0339,  0.8834,  0.1473,  0.0549,\n",
       "         -0.4269, -0.0287,  0.4413,  0.0148, -0.6297,  0.1764, -0.4465, -0.7600,\n",
       "         -0.6015,  0.1211,  0.1748,  0.0158, -0.0852,  0.1104, -0.2929,  0.4816,\n",
       "         -0.5247, -0.3007,  0.4276,  0.2375,  0.0844,  0.4790,  0.2097,  0.4852,\n",
       "          0.2318,  0.6969,  0.3349,  0.0382,  0.2002, -0.0701,  0.0406,  0.1998,\n",
       "          0.0794,  0.1714, -0.3237,  0.2463,  0.1723,  0.3213, -0.2408,  0.1021,\n",
       "          0.0355, -0.1257, -0.0882, -0.0096,  0.1406, -0.6300, -0.0333, -0.3115,\n",
       "          0.2248,  0.1520,  0.3298,  0.3118,  0.6769,  0.0277, -0.1385,  0.0343,\n",
       "         -0.3109,  0.1431, -0.2360, -0.5198, -0.2521,  0.0998, -0.2894,  0.2430,\n",
       "          0.1684, -0.3871, -0.2654,  0.4578,  0.0407,  0.1256,  0.2052,  0.2855,\n",
       "         -0.0671, -0.5463, -0.5364, -0.1295, -0.2031,  0.2879,  0.1756,  0.7379,\n",
       "          0.0144, -0.5159, -0.0746, -0.3060,  0.1450,  0.0841, -0.0449, -0.4885,\n",
       "          0.1494, -0.1555, -0.4062,  0.0619,  0.0464,  0.1580,  0.0389, -0.0466,\n",
       "         -0.3416, -0.1339, -0.1165,  0.4099,  0.1066, -0.2331, -0.0255, -0.0053,\n",
       "         -0.5596,  0.4964,  0.0739, -0.3082,  0.3925,  0.3650, -0.2351,  0.2057,\n",
       "         -0.5471, -0.0303,  0.0631, -0.1057, -0.0727,  0.1157, -0.4364, -0.1291,\n",
       "          0.0300, -0.1515,  0.3603, -0.1893,  0.1436,  0.3276, -0.2293, -0.2903,\n",
       "         -0.5014,  0.6958,  0.1918, -0.1615,  0.1413,  0.4972,  0.1484,  0.1902,\n",
       "          0.0533, -0.1529,  0.0780, -0.2344, -0.5433, -0.4063,  0.3032,  0.3182,\n",
       "         -0.0932, -0.3726,  0.4170,  0.2845, -0.0565,  0.1067,  0.1231, -0.3735,\n",
       "          0.2609, -0.2582, -0.0156, -0.1292,  0.2223,  0.0188,  0.7274,  0.5590,\n",
       "          0.1801, -0.0591, -0.7622, -0.4135, -0.3364, -0.5633, -0.3823, -0.4697,\n",
       "          0.9518, -0.3293,  0.1894,  0.6705,  0.3060, -0.0468, -0.3207,  0.0805,\n",
       "          0.1264, -0.1182, -0.4618,  0.0274,  0.5426, -0.5373,  0.4148,  0.1443,\n",
       "         -0.3454,  0.3400, -0.0778, -0.2446,  0.3069, -0.1342,  0.0803, -0.1670,\n",
       "          0.2596,  0.4059, -0.0017,  0.0457,  0.1983,  0.0994,  0.3085,  0.4298,\n",
       "         -0.1935, -0.0427, -0.5328, -0.2315,  0.0541,  0.0535,  0.0802, -0.5178,\n",
       "          0.2359,  0.0655,  0.2350, -0.1676,  0.0373,  0.2561, -0.0483, -0.0417,\n",
       "          0.1841, -0.0178, -0.5336,  0.0972,  0.3400, -0.2019, -0.4197,  0.3267,\n",
       "          0.0173, -0.2617, -0.0736, -0.1593, -0.2199,  0.2445, -0.0787,  0.2548,\n",
       "         -0.3464, -0.3272, -0.0376,  0.2327, -0.1892, -0.3011, -0.4612,  0.0224,\n",
       "          0.1192,  0.1493, -0.2142, -0.1965, -0.1174, -0.2996,  0.2418,  0.3574,\n",
       "         -0.0224,  0.6134,  0.1329, -0.3891,  0.1725,  0.3868, -0.0647, -0.4991,\n",
       "          0.2969,  0.0798, -0.2838,  0.4735,  0.0726,  0.0874, -0.5351,  0.0406,\n",
       "          0.0085, -0.3792, -0.5631, -0.0774,  0.2384, -0.4358,  0.3406, -0.2793,\n",
       "         -0.0688,  0.0150, -0.3525,  0.1754,  0.3103, -0.1522,  0.0935, -0.2624,\n",
       "          0.0463,  0.4023,  0.4399, -0.4875, -0.0349,  0.6767,  0.7830,  0.7776,\n",
       "          0.0246, -0.0289, -0.3513,  0.6163, -0.1054, -0.2214, -0.9835, -0.0731]],\n",
       "       grad_fn=<ThAddmmBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ResNet()\n",
    "input = V(t.randn(1, 3, 224, 224))\n",
    "out = model(input)\n",
    "out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-learning",
   "language": "python",
   "name": "pytorch-learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
